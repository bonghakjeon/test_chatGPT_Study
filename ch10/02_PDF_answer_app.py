# TODO : ì•„ëž˜ ì˜¤ë¥˜ ë©”ì‹œì§€ í•´ê²°í•˜ê¸° ìœ„í•´ ê°€ìƒí™˜ê²½ "ch10_env" -> í´ë” Lib -> í´ë” site-packages -> í´ë” googletrans -> client.py
#        -> def __init__ ìƒì„±ìžì— ë“¤ì–´ê°€ëŠ” íŒŒë¼ë¯¸í„° "proxies" ìˆ˜ì • (2025.01.17 jbh)
# ì˜¤ë¥˜ ë©”ì‹œì§€ 
# "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. 
# This behaviour is the source of the following dependency conflicts.
# chromadb 0.6.3 requires httpx>=0.27.0, but you have httpx 0.13.3 which is incompatible.      
# langsmith 0.2.10 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible. 
# Successfully installed googletrans-3.1.0a0 h11-0.9.0 httpcore-0.9.1 httpx-0.13.3" 
# ì°¸ê³  URL - https://codemoney.tistory.com/entry/python-error-googletrans%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%ED%98%B8%ED%99%98%EB%AC%B8%EC%A0%9C-httpx%EC%B6%A9%EB%8F%8C
# ì°¸ê³  2 URL - https://stackoverflow.com/questions/72796594/attributeerror-module-httpcore-has-no-attribute-synchttptransport

# def __init__ ìƒì„±ìžì— ë“¤ì–´ê°€ëŠ” íŒŒë¼ë¯¸í„° "proxies" ìˆ˜ì •
# (ìˆ˜ì • ì „) proxies: typing.Dict[str, httpcore.SyncHTTPTransport] = None
# (ìˆ˜ì • í›„) proxies: typing.Dict[str, httpcore.AsyncHTTPProxy] = None


##### ê¸°ë³¸ ì •ë³´ ìž…ë ¥ #####
# Streamlit íŒ¨í‚¤ì§€ ì¶”ê°€
import streamlit as st
# PDF reader - PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ë•Œ ì“°ëŠ” PyPDF2 íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸° 
from PyPDF2 import PdfReader
# Langchain íŒ¨í‚¤ì§€ë“¤
# íŒ¨í‚¤ì§€ langchain-core í„°ë¯¸ë„ ì„¤ì¹˜ ëª…ë ¹ì–´ 
# ì¢…ì†ì„± í•´ê²° ë¬¸ì œë¥¼ í”¼í•˜ë ¤ë©´ ì•„ëž˜ì²˜ëŸ¼ 
# --no-deps ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜
# pip install --no-deps langchain-core==0.3.30
# ì°¸ê³  URL - https://zziii.tistory.com/entry/ERROR-pips-dependency-resolver-does-not-currently-take-into-account-all-the-packages-that-are-installed
from langchain.chat_models import ChatOpenAI
# from langchain_openai import ChatOpenAI
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains.question_answering import load_qa_chain
# êµ¬ê¸€ ë²ˆì—­ API ë¶ˆëŸ¬ì˜¤ê¸°
# êµ¬ê¸€ ë²ˆì—­ê¸° íŒ¨í‚¤ì§€ í„°ë¯¸ë„ ì„¤ì¹˜ ëª…ë ¹ì–´
# ì¢…ì†ì„± í•´ê²° ë¬¸ì œë¥¼ í”¼í•˜ë ¤ë©´ ì•„ëž˜ì²˜ëŸ¼ 
# --no-deps ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜
# pip install --no-deps googletrans==3.1.0a0
# pip install --no-deps googletrans==4.0.0-rc1
# ì°¸ê³  URL - https://github.com/ssut/py-googletrans/issues/400
# ì°¸ê³  2 URL - https://zziii.tistory.com/entry/ERROR-pips-dependency-resolver-does-not-currently-take-into-account-all-the-packages-that-are-installed
from googletrans import Translator

##### ê¸°ëŠ¥ êµ¬í˜„ í•¨ìˆ˜ #####
# ì˜ì–´ë¡œ ëœ í…ìŠ¤íŠ¸ë¥¼ ìž…ë ¥ ë°›ê³  
# êµ¬ê¸€ ë²ˆì—­ê¸° API ê¸°ëŠ¥ì„ í™œìš©í•´ì„œ
# í•œê¸€ ë²ˆì—­ ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥í•´ì£¼ëŠ” í•¨ìˆ˜
def google_trans(messages):
    google = Translator()
    # ì˜ì–´ë¡œëœ í…ìŠ¤íŠ¸(messages)ë¥¼ ìž…ë ¥ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•„ì„œ
    # ì¸ìŠ¤í„´ìŠ¤ ë©”ì„œë“œ google.translate í˜¸ì¶œí•˜ì—¬ ì˜ì–´ -> í•œê¸€ ë²ˆì—­ 
    result = google.translate(messages, dest="ko")
    return result.text   # í•œê¸€ ë²ˆì—­ ê²°ê³¼ ë¦¬í„´  

##### ë©”ì¸ í•¨ìˆ˜ #####
def main():
    # st.set_page_config ì‚¬ìš©í•˜ì—¬ í”„ë¡œê·¸ëž¨ íƒ€ì´í‹€(ì œëª©) "PDF analyzer" ì§€ì •
    st.set_page_config(page_title="PDF analyzer", layout="wide")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:

        # Open AI API í‚¤ ìž…ë ¥ë°›ê¸°
        open_apikey = st.text_input(label='OPENAI API í‚¤', placeholder='Enter Your API Key', value='',type='password')
        
        # ìž…ë ¥ë°›ì€ API í‚¤ í‘œì‹œ
        if open_apikey:
            # LangChain ëª¨ë“ˆì— OpenAI API í‚¤ë¥¼ ë„£ê¸° ìœ„í•´ì„œ
            # st.session_state["OPENAI_API"]ì— OpenAI API í‚¤ ê°’ open_apikey í• ë‹¹ 
            st.session_state["OPENAI_API"] = open_apikey 
        st.markdown('---')
        
    # ë©”ì¸ê³µê°„
    st.header("PDF ë‚´ìš© ì§ˆë¬¸ í”„ë¡œê·¸ëž¨ðŸ“œ") # í”„ë¡œê·¸ëž¨ ì œëª© "PDF ë‚´ìš© ì§ˆë¬¸ í”„ë¡œê·¸ëž¨" ì§€ì • 
    st.markdown('---')
    st.subheader("PDF íŒŒì¼ì„ ë„£ìœ¼ì„¸ìš”") # PDF íŒŒì¼ ì—…ë¡œë“œ í•˜ëŠ” ê¸°ëŠ¥ ìƒë‹¨ì— SubHeader "PDF íŒŒì¼ì„ ë„£ìœ¼ì„¸ìš”" ì§€ì •  
    # PDF íŒŒì¼ ë°›ê¸°
    # í•¨ìˆ˜ st.file_uploader ì‚¬ìš©í•˜ë©´ PDF íŒŒì¼ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ íŒŒì¼ì„ Input(ë˜ëŠ” ì—…ë¡œë“œ) ë°›ì„ ìˆ˜ ìžˆë‹¤.
    # ë“œëž˜ê·¸ ì•¤ ë“œë¡­ ë˜ëŠ” ë²„íŠ¼ Browse files í´ë¦­í•˜ì—¬ PDF íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥ 
    # ì£¼ì˜ì‚¬í•­ - streamlit ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ Input(ë˜ëŠ” ì—…ë¡œë“œ) ë°›ì„ ë•ŒëŠ” 
    #           200 MB ì´í•˜ì¸ íŒŒì¼ë§Œ Input ë°›ì„ ìˆ˜ ìžˆë‹¤.
    #           ì™œëƒí•˜ë©´ ë‚´ë¶€ì ìœ¼ë¡œ ì—°ì‚° ì†ë„ë¥¼ ìµœì í™” ì‹œí‚¤ê¸° ìœ„í•´ì„œ
    #           ë©”ëª¨ë¦¬ ì œí•œ(Limit)ì„ 200 MBë¡œ ê±¸ì–´ë†“ì•˜ê¸° ë•Œë¬¸ì´ë‹¤.
    #           ë‹¨, streamlitì—ì„œëŠ” ë©”ëª¨ë¦¬ ì œí•œ(Limit)ì„ 200 MB ë¥¼ í’€ ìˆ˜ë„ ìžˆë‹¤.
    # ì°¸ê³  URL - https://docs.streamlit.io/develop/api-reference/widgets/st.file_uploader
    # Input(ë˜ëŠ” ì—…ë¡œë“œ)ìœ¼ë¡œ ë°›ì€ íŒŒì¼ ì •ë³´ë¥¼ pdfë¼ëŠ” ë³€ìˆ˜ì— ì €ìž¥ 
    pdf = st.file_uploader(" ", type="pdf")
    
    if pdf is not None:
        # PDF íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ê¸°
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            # PdfReader í´ëž˜ìŠ¤ ê°ì²´ pdf_reader ì‚¬ìš©í•˜ì—¬ 
            # PDF íŒŒì¼ì— ìžˆëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ(page.extract_text()) í•´ì„œ text ë³€ìˆ˜ì— ì €ìž¥ 
            text += page.extract_text()
        # ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê¸°
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        # text_splitter.split_text ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë³€ìˆ˜ textë¥¼
        # chunk ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ë³€ìˆ˜ chunksì— í• ë‹¹ 
        chunks = text_splitter.split_text(text)

        st.markdown('---')
        st.subheader("ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”")
        # ì‚¬ìš©ìž ì§ˆë¬¸ ë°›ê¸°
        # ì‚¬ìš©ìžê°€ ì§ˆë¬¸ ìž…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ë³€ìˆ˜ user_questionì— í• ë‹¹ 
        user_question = st.text_input("Ask a question about your PDF:")
        # ì‚¬ìš©ìžë¡œ ë¶€í„° ì§ˆë¬¸ì„ ìž…ë ¥ë°›ì€ ê²½ìš° (user_question)
        if user_question:
            # ìœ„ì—ì„œ chunk ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ í• ë‹¹í•œ ë³€ìˆ˜ chunksë¥¼  
            # ìž„ë² ë”©/ ì‹œë©˜í‹± ì¸ë±ìŠ¤ ì²˜ë¦¬ ì§„í–‰ 
            # ìž„ë² ë”© í•˜ëŠ” ê²ƒë„ OpenAI API ìš”ê¸ˆ ë¶€ê³¼ë  ìˆ˜ ìžˆê¸° ë•Œë¬¸ì—
            # ì‚¬ìš©ìžë¡œ ë¶€í„° ì§ˆë¬¸ì„ ìž…ë ¥ë°›ì€ ê²½ìš°ì—ë§Œ OpenAI API ìš”ê¸ˆì´ ë¶€ê³¼ë˜ê³  
            # ì‚¬ìš©ìžë¡œ ë¶€í„° ì§ˆë¬¸ì„ ìž…ë ¥ë°›ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” OpenAI API ìš”ê¸ˆì´ ë¶€ê³¼ë˜ì§€ ì•ŠëŠ”ë‹¤.
            embeddings = OpenAIEmbeddings(openai_api_key=st.session_state["OPENAI_API"])
            knowledge_base = FAISS.from_texts(chunks, embeddings)
            
            # í•¨ìˆ˜ knowledge_base.similarity_search ì‚¬ìš©í•´ì„œ 
            # ì§ˆë¬¸(user_question)ê³¼ ê°€ìž¥ ìœ ì‚¬í•œ chunkë“¤ì„ ì¶”ì¶œí•´ì„œ ë³€ìˆ˜ docsì— ì €ìž¥
            docs = knowledge_base.similarity_search(user_question)

            # ì§ˆë¬¸í•˜ê¸°
            # ChatOpenAI í´ëž˜ìŠ¤ ê°ì²´ llm ìƒì„± ë° 
            # ChatGPTì˜ ì–¸ì–´ ëª¨ë¸ ì„¤ì •(model_name='gpt-3.5-turbo')
            llm = ChatOpenAI(temperature=0,
                    openai_api_key=st.session_state["OPENAI_API"],
                    max_tokens=2000,
                    model_name='gpt-3.5-turbo',
                    request_timeout=120
                    )
            # í•¨ìˆ˜ load_qa_chain ì‚¬ìš©í•´ì„œ ì¸ìŠ¤í„´ìŠ¤ chain ìƒì„± 
            chain = load_qa_chain(llm, chain_type="stuff")
            # ë‹µë³€ì— ì‚¬ìš©í•  chunkê°’ì´ ë‹´ê¸´ ë³€ìˆ˜ docsë¥¼ í•¨ìˆ˜ chain.runì˜ ìž…ë ¥ íŒŒë¼ë¯¸í„° ê°’ìœ¼ë¡œ ë„£ì–´ì£¼ê³ 
            # ì‚¬ìš©ìžì˜ ì§ˆë¬¸(user_question) ë˜í•œ í•¨ìˆ˜ chain.runì˜ ìž…ë ¥ íŒŒë¼ë¯¸í„° ê°’ìœ¼ë¡œ ë„£ì–´ì¤€ë‹¤.
            # ChatGPTë¡œ ë¶€í„° ì–»ì€ ë‹µë³€ ê²°ê³¼ë¥¼ ë³€ìˆ˜ responseì— ì €ìž¥ 
            response = chain.run(input_documents=docs, question=user_question)
            # ë‹µë³€ê²°ê³¼
            # st.info ì‚¬ìš©í•˜ì—¬ ChatGPTë¡œ ë¶€í„° ì–»ì€ ë‹µë³€ ê²°ê³¼ í™”ë©´ ì¶œë ¥ 
            st.info(response)
            #í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê¸°
            # ë²„íŠ¼ "ë²ˆì—­í•˜ê¸°" í´ë¦­í•œ ê²½ìš°
            if st.button(label="ë²ˆì—­í•˜ê¸°"):
                # ChatGPTë¡œ ë¶€í„° ì–»ì€ ë‹µë³€ ê²°ê³¼ê°€ ë‹´ê¸´ ë³€ìˆ˜ responseë¥¼
                # í•¨ìˆ˜ google_transì˜ ì¸ìžê°’ìœ¼ë¡œ ì „ë‹¬ 
                # ì˜ì–´ -> í•œê¸€ë¡œ ë²ˆì—­í•œ ë‹µë³€ ê²°ê³¼ë¥¼ ë³€ìˆ˜ transì— ì €ìž¥
                trans = google_trans(response)
                st.success(trans) # st.success ì‚¬ìš©í•´ì„œ í”„ë¡œê·¸ëž¨ì— ì˜ì–´ -> í•œê¸€ë¡œ ë²ˆì—­í•œ ë‹µë³€ ê²°ê³¼ ì¶œë ¥ 

if __name__=='__main__':
    main()